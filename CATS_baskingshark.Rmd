---
title: "CATS_basker_analysis"
output: html_document
---

Here I'm going to bring in the initial raw dataset from CATSCam, shark 2
```{r}
library(rmarkdown)
library(ggplot2)
setwd("~/Desktop/Basking sharks/bs.git")
ID <- 3 #this allows us to change the ID to look at other data if we want to 
data <- read.csv(paste0("Shark ", ID, "_CATS.csv"))
head(data)
table(data$Date) #all have the same date (July 26, 2013)
data$Time[1] #first time: 19:16:45
data$Time[nrow(data)] #end time: 22:10:47
```
**SUMMARY STATS** we need to think about what we are interested in. We want to know time, feeding, pressure, temperature, light intensity, ODBA

```{r}
dat2 <- data[,c(2,4, 5, 12, 19, 20, 21, 22)]
head(dat2)
#convert time to POSIXct
dat2[,1] <- as.POSIXct(dat2$Time, format="%H:%M:%OS", tz="UTC")
head(dat2)
colnames(dat2) <- c("Time", "Feeding", "Pressure", "Temp1", "Temp2", "Light", "Temp.ext", "ODBA") #still don't know what some of these things are - need to ask Heather
```


Let's look at frequency distribution of feeding events. To do this, we will first need to figure out how to define a single "feeding event". We can think of this in terms of the minimum time difference that needs to happen in order for feeding behavior to be considered another "feeding event" (so, 20 seconds? 30 seconds?). Anything less than that would be considered the same feeding event. Then, we need to go through each segment and figure out how long these segments are (subtract time that the event began from the time that it ended). 
```{r}
feed.dat <- dat2[dat2$Feeding==1,]
summary(feed.dat)
# need to bin by duration of feeding event, which requires defining feeding events
feed.dat$Time
length(feed.dat$Time)
# should define feeding events by any difference in time between events > 00:20 (aka they stop feeding for 20 seconds; otherwise considered the same feeding event)
interv <- feed.dat$Time[-1]-feed.dat$Time[-length(feed.dat$Time)]
table(interv)
splits <- which(interv > 30) #this gives us the locations of where the difference is greater than 10
length(splits)
head(feed.dat)

#### practice with one segment of feeding behavior: 

feed.dat1 <- (feed.dat[0:splits[1],])
ft1 <- feed.dat1[nrow(feed.dat1),1] - feed.dat1[1,1] #returns a difftime object and time difference that gives you the duration of the feeding event
ft1 <- as.numeric(feed.dat1[nrow(feed.dat1),1] - feed.dat1[1,1]) #make numeric

# ### now try with two segments, and combine in a list
feed.dat2 <- (feed.dat[splits[1]:splits[2],])
 ft2 <- as.numeric(feed.dat2[nrow(feed.dat2),1] - feed.dat2[1,1]) 
# 
# feed.dat3 <- (feed.dat[splits[2]:splits[3],])
# ft3 <- as.numeric(feed.dat3[nrow(feed.dat3),1] - feed.dat3[1,1]) 
# 
# #create a vector with the ft values
# vec <- c(ft1, ft2)
# hist(vec)

#### now, to combine all of these in a for loop in order to get a vector that contains the number of seconds per feeding bout (assuming the threshold for feeding/non-feeding is 10 seconds)

ft <- c(ft1, rep(NA,length(splits)-1)) #did ft1 manually because it was easier

for(i in 2:length(splits)){
  temp <- feed.dat[splits[i-1]:splits[i],]
  ft1 <- as.numeric(temp[nrow(temp),1] - temp[1,1])
  ft[i] <- ft1
}

breaks <- seq(from=1, to=100, 5)
hist(ft, breaks=breaks, main = "Histogram of Feeding Events", xlab = "Duration of Event (s)")



```
**ACCELEROMETER INFO** Now we want to go back to the original data set, and pull out the time, whether it was a feeding event, then the acceleration in each axis 

```{r}
head(data)
summary(data)
acc <- data[,c(2, 4, 11, 13, 15)]
head(acc)
# note: all of our accelerations are in g. 1 g = 9.80665 m/s^2, so we need to convert all of our axes
acc$Sway <- acc$Sway..g.*9.80665
acc$Surge<- acc$Surge..g.*9.80665
acc$Heave <- acc$Heave..g.*9.80665
head(acc)

acc[,1] <- as.POSIXct(acc$Time, format="%H:%M:%OS", tz="UTC")
summary(acc$Time)

# we have VERY high frequency. Probably can subsample, by removing duplicated timestamps (because we took off the milliseconds and such, so now we only have seconds)
acc_sub <- acc[!duplicated(acc[,1]),]
head(acc_sub)
summary(acc_sub)
nrow(acc_sub)
plot(acc_sub$Time[1:500], acc_sub$X0.Not.Feeding.1.Feeding[50:90])

#### now that we have narrowed down a sample feeding event from the plot above ###
#practice visualizing acceleration data overall
ggplot(data=acc_sub, aes(x=Time, y=Surge)) + geom_line() + geom_line(aes(x=Time, y=Sway, color="red")) + geom_line(aes(x=Time, y=Heave, color="blue"))

#Brownscombe et al., 2013: oscillations in the sway axis are good proxy for TB frequency
ggplot(data=acc_sub[1:100,], aes(x=Time, y=X0.Not.Feeding.1.Feeding)) + geom_point()
# can see that there is a feeding event from "2018-07-27 19:51:00" to "2018-07-27 19:51:00"
ggplot(data=acc_sub[230:420,], aes(x=Time, y=Sway)) + geom_line()

# make same scale so can compare
ggplot(data=acc_sub[300:340,], aes(x=Time, y=Sway)) + geom_line()
# not feeding
ggplot(data=acc_sub[1:40,], aes(x=Time, y=Sway)) + geom_line()

```
Trying to play with signal processing. Note that for this signal, we want to run a high pass filter, because we WANT all of those tiny details and to get rid of the static acceleration. Filters work by computing the output from a number of input samples. 
The number of samples is the memory length of the filter (Mark Johnson, St. Andrews). FIR (with finite memory) are better for processing movement data, rather than IIR (eg Butterworth, infinite memory, better for processing sound). We can use a Moving Average (MA) to make a high pass filter, where the memory is n-1 samples and the output is the mean of the last n samples. OR we can use a filter that is delay free and based on window functions. These have longer memories. 


```{r}
library(stats)
sway <- data.frame(acc_sub$Sway, acc_sub$Time)
colnames(sway) <- c("Sway", "Time")
summary(sway)
str(sway)
plot(sway$Sway~sway$Time,type="l")

# we are looking just at the signature for sway. I ultimately want a high pass filter to try to get rid of any static acceleration 

## playing with high pass filters using the "filter" function
# fir1(n, w, type = c("low", "high", "stop", "pass", "DC-0", "DC-1"),
# window = hamming(n + 1), scale = TRUE) 
# n = order of filter, degree of polynomial that will be used to smooth data; w = band edges between 0-1 (cut off point for filter), type = type of filter

# generating MA coefficients for the filter I want to use 
flt <- fir1(10, .9, type="high") # n must be even for high pass filters
# note: you can play around with the order of the polynomial to get an even smoother track

# now applying the filter:
filtering <- filter(flt, sway$Sway)
plot(filtering[1:100]~sway$Time[1:100], type ="l")
lines(sway$Sway[1:100]~sway$Time[1:100], col="red")

### Can also apply the filter using a fast fourier transform, which breaks down the signal into different harmonics ### 
fftfilt(b, x, n = NULL) # b= moving average coefficients (from flt), x= signal to be filtered, n = length of FFT window 
fourier <- fftfilt(flt, sway$Sway)
plot(sway$Time, sway$Sway, type = "l")
lines(sway$Time, fourier, col = "red")

# let's compare the two filtering methods (fft and filter)
plot(sway$Time, sway$Sway, type = "l")
plot(sway$Time, fourier, type= "l", col = "red")
lines(filtering~sway$Time, col="blue")
## COOL! They're basically the same ## 

# now, for fun, let's try a low pass filter # 
# generating MA coefficients for the filter I want to use 
flt.low <- fir1(8, .3, type="low")
filtering.low <- filter(flt.low, sway$Sway)
plot(filtering.low[1:100]~sway$Time[1:100], type ="l")
lines(sway$Sway[1:100]~sway$Time[1:100], col="red")
# we can see that this "smooths" the track and gets rid of all of that noise. BUT you can also see that there's a bit of a delay because of the nature of the MA coefficients # 
# delay = (n-1)/2 or half of memory time #

```